{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1c368-1b6f-4b34-9550-7b98912f8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install minisom\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, SpectralClustering, OPTICS, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, homogeneity_score, completeness_score, v_measure_score\n",
    "from minisom import MiniSom\n",
    "\n",
    "scaler = StandardScaler()\n",
    "moment_lst_scaled = scaler.fit_transform(moment_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cda0c7-723d-4372-94b9-5adca3088f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moments(storm):\n",
    "  # A function to calculate the track moments given a storm\n",
    "  # OUTPUT:\n",
    "  # X-centroid, Y-centroid, X_var, Y_var, XY_var\n",
    "\n",
    "  # Note that:\n",
    "  # In this case, no weights are set. In other words, all weights are 1.\n",
    "  # A weight variable would need to be added in order to explore other weights\n",
    "\n",
    "  lon_lst, lat_lst = get_lon_lat(storm)\n",
    "  # If the track only has one point, there is no point in calculating the moments\n",
    "  if len(lon_lst)<= 1: return [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "      \n",
    "  # M1 (first moment = mean). \n",
    "  # No weights applied\n",
    "  lon_weighted, lat_weighted = np.mean(lon_lst), np.mean(lat_lst)\n",
    "    \n",
    "  # M2 (second moment = variance of lat and of lon / covariance of lat to lon\n",
    "  # No weights applied\n",
    "  cv = np.ma.cov([lon_lst, lat_lst])\n",
    "    \n",
    "  return [lon_weighted, lat_weighted, cv[0, 0], cv[1, 1], cv[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17580328-d48c-458e-88ad-a947befcedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_lst = [get_moments(tks.sel(storm=i)) for i in range(tks.dims['storm'])\n",
    "              if get_moments(tks.sel(storm=i))]\n",
    "print(np.shape(moment_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e01ec89-6ee1-4298-b423-9ff73c050916",
   "metadata": {},
   "source": [
    "#### 0-(1) Extreme value at each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f58a1-2cb6-4fd6-917f-a65c73f80b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_storms = tks.dims['storm']\n",
    "# (0)PDI\n",
    "PDI_max_wmo = np.full((num_storms, 1), np.nan)\n",
    "PDI_max_usa = np.full((num_storms, 1), np.nan)\n",
    "PDI_max_tokyo = np.full((num_storms, 1), np.nan)\n",
    "# (1)min Pressure\n",
    "Pres_min_wmo = np.full((num_storms, 1), np.nan)\n",
    "# (3)max storm radius  \n",
    "r34_max_wmo = np.full((num_storms, 1), np.nan)\n",
    "r50_max_wmo = np.full((num_storms, 1), np.nan)\n",
    "r64_max_wmo = np.full((num_storms, 1), np.nan)\n",
    "eye_max_wmo = np.full((num_storms, 1), np.nan)\n",
    "# (4)Eye of the Storm (max) \n",
    "eye_max_wmo = np.full((num_storms, 1), np.nan)\n",
    "# (5)Storm speed (translation speed)\n",
    "storm_speed_max_wmo = np.full((num_storms, 1), np.nan)\n",
    "# (6)seasons\n",
    "storm_season_wmo = np.full((num_storms, 1), np.nan)\n",
    "# (7)day of year\n",
    "DayofYear_mean = np.full((num_storms, 1), np.nan)\n",
    "for k in range(num_storms):\n",
    "    tks_stormk = tks.isel(storm=k)\n",
    "    t_stormk = tks_stormk['time'].values\n",
    "    dt_stormk_s = np.nanmean( np.diff(t_stormk) * 3600 )\n",
    "\n",
    "    # (0)PDI\n",
    "    u_stormk = tks_stormk['wmo_wind'].values\n",
    "    PDI_max_wmo[k] = np.nanmax( u_stormk**3  *  np.nanmean(np.diff(t_stormk) * 3600) )\n",
    "    u_stormk = tks_stormk['usa_wind'].values\n",
    "    PDI_max_usa[k] = np.nanmax( u_stormk**3  *  np.nanmean(np.diff(t_stormk) * 3600) )\n",
    "    u_stormk = tks_stormk['tokyo_wind'].values\n",
    "    PDI_max_tokyo[k] = np.nanmax( u_stormk**3  *  np.nanmean(np.diff(t_stormk) * 3600) )\n",
    "\n",
    "    # (1)min Pressure\n",
    "    Pres_min_wmo[k] = np.nanmin(tks_stormk['wmo_pres'].values)\n",
    "    \n",
    "    # (3)max storm radius  \n",
    "    # reunion_r34  tokyo_r50_short  tokyo_r30_short has no data\n",
    "    r34_max_wmo[k] = np.nanmax(tks_stormk['usa_r34'].values)\n",
    "    r50_max_wmo[k] = np.nanmax(tks_stormk['usa_r50'].values)\n",
    "    r64_max_wmo[k] = np.nanmax(tks_stormk['usa_r64'].values)\n",
    "\n",
    "    # (4)Eye of the Storm (max) \n",
    "    eye_max_wmo[k] = np.nanmax(tks_stormk['usa_eye'].values)\n",
    "    \n",
    "    # (5)Storm speed (translation speed)\n",
    "    storm_speed_max_wmo[k] = np.nanmax(tks_stormk['storm_speed'].values)\n",
    "    \n",
    "    # (6)Storm speed (translation speed)\n",
    "    storm_season_wmo[k] = np.nanmax(tks_stormk['season'].values)\n",
    "\n",
    "    # (7)day of year\n",
    "    reference_time = pd.Timestamp(\"1858-11-17\")\n",
    "    datetime_values = reference_time + pd.to_timedelta(t_stormk, unit=\"D\")\n",
    "    DayofYear_mean[k] = np.nanmean(datetime_values.dayofyear)\n",
    "\n",
    "PDI_max_wmo = np.ravel(PDI_max_wmo) \n",
    "PDI_max_usa = np.ravel(PDI_max_usa)  \n",
    "PDI_max_tokyo = np.ravel(PDI_max_tokyo)  \n",
    "Pres_min_wmo = np.ravel(Pres_min_wmo)  \n",
    "r34_max_wmo = np.ravel(r34_max_wmo)  \n",
    "r50_max_wmo = np.ravel(r50_max_wmo)  \n",
    "r64_max_wmo = np.ravel(r64_max_wmo)  \n",
    "eye_max_wmo = np.ravel(eye_max_wmo)  \n",
    "storm_speed_max_wmo = np.ravel(storm_speed_max_wmo)  \n",
    "DayofYear_mean = np.ravel(DayofYear_mean)  \n",
    "moment_array = np.array(moment_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721d106-e169-433f-83f2-493586bf62ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c661b1f-bfd8-4563-84f2-851e0ec7454f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b1f06-6edb-4dcc-b64d-602f765d0401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb2ab41-35bb-4f9d-816a-88a2bc0e0a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0de443-0967-4ff4-a222-eb24335759bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a664a0-c3a7-46ce-93a4-fe4ccebdef31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
